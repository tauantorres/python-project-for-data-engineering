{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries\n",
    "\n",
    "Import the following four libraries by adding lines of code noted below to your `webscraping_movies.py` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization of known entities\n",
    "---\n",
    "\n",
    "You must declare a few entities at the beginning. For example, you know the required `URL`, the `CSV` name for saving the record, the database name, and the table name for storing the record. You also know the entities to be saved. \n",
    "\n",
    "Additionally, since you require only the top 50 results, you will require a loop counter initialized to 0.\n",
    " \n",
    "You may initialize all these by using the following code in `webscraping_movies.py`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://web.archive.org/web/20230902185655/https://en.everybodywiki.com/100_Most_Highly-Ranked_Films'\n",
    "count = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_BASE = '../week-01/material/'\n",
    "\n",
    "csv_path = PATH_BASE + 'top_50_films.csv'\n",
    "table_name = PATH_BASE + 'Top_50'\n",
    "db_name = PATH_BASE + 'Movies.db'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE 1\n",
    "\n",
    "csv_path = PATH_BASE + 'top_50_films_EXERCISE_01.csv'\n",
    "table_name = PATH_BASE + 'Top_50_EXERCISE_01'\n",
    "db_name = PATH_BASE + 'Movies_EXERCISE_01.db'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=[\"Film\", \"Year\", \"Rotten Tomatoes' Top 100\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the webpage for Webscraping\n",
    "---\n",
    "\n",
    "To access the required information from the web page, you first need to load the entire web page as an `HTML` document in `python` using the `requests.get().text` function and then parse the text in the `HTML` format using `BeautifulSoup` to enable extraction of relevant information.\n",
    "\n",
    "Add the following code to `webscraping_movies.py`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_page = requests.get(url).text\n",
    "data = BeautifulSoup(html_page, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping of required information\n",
    "\n",
    "You now need to write the loop to extract the appropriate information from the web page. The rows of the table needed can be accessed using the `find_all()` function with the `BeautifulSoup` object using the statements below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = data.find_all('tbody')\n",
    "rows = tables[0].find_all('tr')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the variable `tables` gets the body of all the tables in the web page and the variable `rows` gets all the rows of the first table.\n",
    "\n",
    "You can now iterate over the rows to find the required data. Use the code shown below to extract the information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_K = 25\n",
    "\n",
    "for row in rows:\n",
    "    if count < top_K:\n",
    "        col = row.find_all('td')\n",
    "        if len(col)!=0:\n",
    "            data_dict = {\"Average Rank\": col[0].contents[0],\n",
    "                         \"Film\": col[1].contents[0],\n",
    "                         \"Year\": col[2].contents[0]}\n",
    "            df1 = pd.DataFrame(data_dict, index=[0])\n",
    "            df = pd.concat([df,df1], ignore_index=True)\n",
    "            count+=1\n",
    "    else:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE 1\n",
    "top_K = 25\n",
    "\n",
    "for row in rows:\n",
    "    if count < top_K:\n",
    "        col = row.find_all('td')\n",
    "        if len(col)!=0:\n",
    "            data_dict = {\"Film\": col[1].contents[0],\n",
    "                         \"Year\": col[2].contents[0],\n",
    "                         \"Rotten Tomatoes' Top 100\": col[3].contents[0]}\n",
    "            df1 = pd.DataFrame(data_dict, index=[0])\n",
    "            df = pd.concat([df,df1], ignore_index=True)\n",
    "            count+=1\n",
    "    else:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code functions as follows.\n",
    "\n",
    "1. Iterate over the contents of the variable `rows`.\n",
    "2. Check for the loop counter to restrict to 50 entries.\n",
    "3. Extract all the `td` data objects in the row and save them to `col`.\n",
    "4. Check if the length of `col` is 0, that is, if there is no data in a current row. This is important since, many timesm there are merged rows that are not apparent in the web page appearance.\n",
    "5. Create a dictionary `data_dict` with the keys same as the columns of the dataframe created for recording the output earlier and corresponding values from the first three headers of data.\n",
    "6. Convert the dictionary to a dataframe and concatenate it with the existing one. This way, the data keeps getting appended to the dataframe with every iteration of the loop.\n",
    "7. Increment the loop counter.\n",
    "8. Once the counter hits 50, stop iterating over rows and break the loop.\n",
    "\n",
    "\n",
    "Print the contents of the dataframe using the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Film  Year Rotten Tomatoes' Top 100\n",
      "0           The Godfather  1972                       17\n",
      "1            Citizen Kane  1941                        2\n",
      "2              Casablanca  1942                        8\n",
      "3  The Godfather, Part II  1974                       99\n",
      "4     Singin' in the Rain  1952                       52\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter\n",
    "---\n",
    "\n",
    "Filter the output to print only the films released in the 2000s (year 2000 included).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Film</th>\n",
       "      <th>Year</th>\n",
       "      <th>Rotten Tomatoes' Top 100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Parasite</td>\n",
       "      <td>2019</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Lord of the Rings: The Fellowship of the Ring</td>\n",
       "      <td>2001</td>\n",
       "      <td>unranked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Avengers: Endgame</td>\n",
       "      <td>2019</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Film  Year  \\\n",
       "16                                       Parasite  2019   \n",
       "18  Lord of the Rings: The Fellowship of the Ring  2001   \n",
       "22                              Avengers: Endgame  2019   \n",
       "\n",
       "   Rotten Tomatoes' Top 100  \n",
       "16                        6  \n",
       "18                 unranked  \n",
       "22                        7  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filter = df[df['Year'] >= '2000']\n",
    "df_filter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing the data\n",
    "---\n",
    "\n",
    "After the dataframe has been created, you can save it to a CSV file using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE 1\n",
    "df_filter.to_csv(csv_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that you defined the variable `csv_path` earlier.\n",
    "\n",
    "To store the required data in a database, you first need to initialize a connection to the database, save the dataframe as a table, and then close the connection. This can be done using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(db_name)\n",
    "df.to_sql(table_name, conn, if_exists='replace', index=False)\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE 1\n",
    "conn = sqlite3.connect(db_name)\n",
    "df_filter.to_sql(table_name, conn, if_exists='replace', index=False)\n",
    "conn.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
